#!/usr/bin/env python3
"""
å¿«é€ŸGPUæµ‹è¯•å¯åŠ¨è„šæœ¬
è‡ªåŠ¨æ£€æµ‹GPUç¯å¢ƒå¹¶è¿è¡Œé€‚åˆçš„æµ‹è¯•
"""

import sys
import os
import logging
import torch
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

def setup_logging():
    """è®¾ç½®æ—¥å¿—"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

def check_requirements():
    """æ£€æŸ¥åŸºæœ¬è¦æ±‚"""
    logger = logging.getLogger(__name__)
    
    # æ£€æŸ¥CUDA
    if not torch.cuda.is_available():
        logger.error("âŒ CUDAä¸å¯ç”¨ï¼Œæ— æ³•è¿è¡ŒGPUæµ‹è¯•")
        logger.error("è¯·å®‰è£…æ”¯æŒCUDAçš„PyTorchç‰ˆæœ¬")
        return False
    
    # æ£€æŸ¥æ•°æ®é›†
    dataset_dir = Path("data/datasets")
    if not dataset_dir.exists() or not list(dataset_dir.glob("benchmark_dataset_config_*.jsonl")):
        logger.error("âŒ æœªæ‰¾åˆ°æµ‹è¯•æ•°æ®é›†")
        logger.info("æ­£åœ¨ç”Ÿæˆæ•°æ®é›†...")
        
        try:
            # è¿è¡Œæ•°æ®é›†ç”Ÿæˆ
            os.system("python scripts/generate_dataset.py")
            
            # å†æ¬¡æ£€æŸ¥
            if not list(dataset_dir.glob("benchmark_dataset_config_*.jsonl")):
                logger.error("æ•°æ®é›†ç”Ÿæˆå¤±è´¥")
                return False
            
            logger.info("âœ… æ•°æ®é›†ç”ŸæˆæˆåŠŸ")
            
        except Exception as e:
            logger.error(f"æ•°æ®é›†ç”Ÿæˆå¤±è´¥: {e}")
            return False
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶
    config_files = [
        "config/model_config.yaml",
        "config/inference_config.yaml",
        "config/data_config.yaml"
    ]
    
    for config_file in config_files:
        if not Path(config_file).exists():
            logger.error(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
            return False
    
    logger.info("âœ… åŸºæœ¬è¦æ±‚æ£€æŸ¥é€šè¿‡")
    return True

def detect_gpu_setup():
    """æ£€æµ‹GPUé…ç½®"""
    logger = logging.getLogger(__name__)
    
    gpu_count = torch.cuda.device_count()
    logger.info(f"æ£€æµ‹åˆ° {gpu_count} ä¸ªGPU:")
    
    gpu_info = []
    total_memory = 0
    
    for i in range(gpu_count):
        gpu_name = torch.cuda.get_device_name(i)
        gpu_memory = torch.cuda.get_device_properties(i).total_memory / (1024**3)
        total_memory += gpu_memory
        
        gpu_info.append({
            'id': i,
            'name': gpu_name,
            'memory_gb': gpu_memory
        })
        
        logger.info(f"  GPU {i}: {gpu_name} ({gpu_memory:.1f} GB)")
    
    logger.info(f"æ€»GPUå†…å­˜: {total_memory:.1f} GB")
    
    return gpu_info

def recommend_test_strategy(gpu_info):
    """æ¨èæµ‹è¯•ç­–ç•¥"""
    logger = logging.getLogger(__name__)
    
    gpu_count = len(gpu_info)
    total_memory = sum(gpu['memory_gb'] for gpu in gpu_info)
    
    logger.info(f"\nğŸ¯ æ¨èçš„æµ‹è¯•ç­–ç•¥:")
    
    if gpu_count == 1:
        if gpu_info[0]['memory_gb'] >= 8:
            logger.info("âœ… å•GPUé…ç½®ï¼Œå†…å­˜å……è¶³")
            logger.info("æ¨èï¼šè¿è¡Œå®Œæ•´çš„å•GPUæ€§èƒ½åŸºå‡†æµ‹è¯•")
            return "single_gpu_full"
        else:
            logger.info("âš ï¸  å•GPUé…ç½®ï¼Œå†…å­˜æœ‰é™")
            logger.info("æ¨èï¼šè¿è¡Œè½»é‡çº§çš„å•GPUæµ‹è¯•")
            return "single_gpu_light"
    
    elif gpu_count >= 2:
        logger.info(f"âœ… å¤šGPUé…ç½® ({gpu_count} ä¸ªGPU)")
        logger.info("æ¨èï¼šè¿è¡Œåˆ†å¸ƒå¼æ¨ç†æ€§èƒ½æµ‹è¯•")
        if total_memory >= 32:
            logger.info("å†…å­˜å……è¶³ï¼Œå¯è¿è¡Œå®Œæ•´æµ‹è¯•")
            return "multi_gpu_full"
        else:
            logger.info("å†…å­˜æœ‰é™ï¼Œå»ºè®®è½»é‡çº§æµ‹è¯•")
            return "multi_gpu_light"
    
    return "single_gpu_light"

def run_test_strategy(strategy):
    """æ‰§è¡Œæµ‹è¯•ç­–ç•¥"""
    logger = logging.getLogger(__name__)
    
    logger.info(f"\nğŸš€ æ‰§è¡Œæµ‹è¯•ç­–ç•¥: {strategy}")
    
    if strategy == "single_gpu_full":
        logger.info("è¿è¡Œå®Œæ•´å•GPUåŸºå‡†æµ‹è¯•...")
        cmd = "python gpu_benchmark.py --max-samples-per-config 100"
        
    elif strategy == "single_gpu_light":
        logger.info("è¿è¡Œè½»é‡çº§å•GPUæµ‹è¯•...")
        cmd = "python gpu_benchmark.py --max-samples-per-config 20"
        
    elif strategy == "multi_gpu_full":
        gpu_count = torch.cuda.device_count()
        logger.info(f"è¿è¡Œå®Œæ•´å¤šGPUåŸºå‡†æµ‹è¯• ({gpu_count} GPUs)...")
        cmd = f"python gpu_benchmark.py --num-gpus {gpu_count} --max-samples-per-config 50"
        
    elif strategy == "multi_gpu_light":
        gpu_count = torch.cuda.device_count()
        logger.info(f"è¿è¡Œè½»é‡çº§å¤šGPUæµ‹è¯• ({gpu_count} GPUs)...")
        cmd = f"python gpu_benchmark.py --num-gpus {gpu_count} --max-samples-per-config 10"
        
    else:
        logger.error(f"æœªçŸ¥çš„æµ‹è¯•ç­–ç•¥: {strategy}")
        return False
    
    logger.info(f"æ‰§è¡Œå‘½ä»¤: {cmd}")
    
    try:
        result = os.system(cmd)
        return result == 0
    except Exception as e:
        logger.error(f"æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
        return False

def main():
    setup_logging()
    logger = logging.getLogger(__name__)
    
    logger.info("="*60)
    logger.info("ğŸ¯ GPUæ¨ç†æµ‹è¯•å¿«é€Ÿå¯åŠ¨")
    logger.info("="*60)
    
    # æ£€æŸ¥åŸºæœ¬è¦æ±‚
    if not check_requirements():
        logger.error("åŸºæœ¬è¦æ±‚æ£€æŸ¥å¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
        sys.exit(1)
    
    # æ£€æµ‹GPUé…ç½®
    gpu_info = detect_gpu_setup()
    
    # æ¨èæµ‹è¯•ç­–ç•¥
    strategy = recommend_test_strategy(gpu_info)
    
    # è¯¢é—®ç”¨æˆ·ç¡®è®¤
    print(f"\næ˜¯å¦æ‰§è¡Œæ¨èçš„æµ‹è¯•ç­–ç•¥ï¼Ÿ (y/n): ", end="")
    try:
        user_input = input().strip().lower()
        if user_input not in ['y', 'yes', '']:
            logger.info("ç”¨æˆ·å–æ¶ˆæµ‹è¯•")
            sys.exit(0)
    except KeyboardInterrupt:
        logger.info("\nç”¨æˆ·å–æ¶ˆæµ‹è¯•")
        sys.exit(0)
    
    # æ‰§è¡Œæµ‹è¯•
    success = run_test_strategy(strategy)
    
    if success:
        logger.info("\nğŸ‰ GPUæ¨ç†æµ‹è¯•å®Œæˆï¼")
        logger.info("æŸ¥çœ‹ results/ ç›®å½•è·å–è¯¦ç»†ç»“æœ")
        logger.info("æŸ¥çœ‹ logs/ ç›®å½•è·å–è¯¦ç»†æ—¥å¿—")
    else:
        logger.error("\nâŒ GPUæ¨ç†æµ‹è¯•å¤±è´¥")
        logger.info("è¯·æ£€æŸ¥æ—¥å¿—æ–‡ä»¶äº†è§£è¯¦ç»†é”™è¯¯ä¿¡æ¯")
        sys.exit(1)

if __name__ == "__main__":
    main()
