#!/usr/bin/env python3
"""
GPUæ¨ç†æ€§èƒ½åŸºå‡†æµ‹è¯•
ä¸“é—¨ç”¨äºGPUç¯å¢ƒä¸‹çš„åˆ†å¸ƒå¼æ¨ç†æ€§èƒ½æµ‹è¯•
æ”¯æŒå•GPUå’Œå¤šGPUå¹¶è¡Œç­–ç•¥
"""

import sys
import os
import argparse
import logging
import torch
import time
from pathlib import Path
import json

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

def setup_logging(rank: int = 0, log_level: str = "INFO") -> None:
    """è®¾ç½®æ—¥å¿—"""
    log_dir = Path("logs")
    log_dir.mkdir(exist_ok=True)
    
    logging.basicConfig(
        level=getattr(logging, log_level.upper()),
        format=f'[GPU-{rank}] %(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler(f'logs/gpu_inference_test_rank_{rank}.log')
        ]
    )

def validate_gpu_environment(min_gpus: int = 1):
    """éªŒè¯GPUç¯å¢ƒ"""
    logger = logging.getLogger(__name__)
    
    if not torch.cuda.is_available():
        logger.error("âŒ CUDAä¸å¯ç”¨ï¼")
        logger.error("è¯·ç¡®ä¿ï¼š")
        logger.error("1. å®‰è£…äº†æ”¯æŒCUDAçš„PyTorchç‰ˆæœ¬")
        logger.error("2. ç³»ç»Ÿä¸­æœ‰å¯ç”¨çš„NVIDIA GPU")
        logger.error("3. æ­£ç¡®å®‰è£…äº†CUDAé©±åŠ¨å’Œå·¥å…·åŒ…")
        return False
    
    gpu_count = torch.cuda.device_count()
    if gpu_count < min_gpus:
        logger.error(f"âŒ éœ€è¦è‡³å°‘ {min_gpus} ä¸ªGPUï¼Œä½†åªæ£€æµ‹åˆ° {gpu_count} ä¸ª")
        return False
    
    logger.info(f"âœ… GPUç¯å¢ƒéªŒè¯é€šè¿‡ï¼Œæ£€æµ‹åˆ° {gpu_count} ä¸ªGPUï¼š")
    
    for i in range(gpu_count):
        gpu_name = torch.cuda.get_device_name(i)
        gpu_memory = torch.cuda.get_device_properties(i).total_memory / (1024**3)
        logger.info(f"   GPU {i}: {gpu_name} ({gpu_memory:.1f} GB)")
    
    return True

def load_test_dataset(dataset_dir: str, max_samples_per_config: int = None):
    """åŠ è½½æµ‹è¯•æ•°æ®é›†"""
    logger = logging.getLogger(__name__)
    
    from src.utils import DataLoader
    
    dataset_files = list(Path(dataset_dir).glob("benchmark_dataset_config_*.jsonl"))
    if not dataset_files:
        logger.error(f"æœªåœ¨ {dataset_dir} ä¸­æ‰¾åˆ°æ•°æ®é›†æ–‡ä»¶")
        return None
    
    logger.info(f"æ‰¾åˆ° {len(dataset_files)} ä¸ªé…ç½®æ–‡ä»¶")
    
    all_samples = []
    config_stats = {}
    
    for config_file in dataset_files:
        try:
            data_loader = DataLoader(str(config_file))
            samples = data_loader.load_samples()
            
            if max_samples_per_config and len(samples) > max_samples_per_config:
                samples = samples[:max_samples_per_config]
                logger.info(f"é…ç½®æ–‡ä»¶ {config_file.name}ï¼šé™åˆ¶ä¸º {max_samples_per_config} ä¸ªæ ·æœ¬")
            
            config_id = samples[0].config_id if samples else "unknown"
            config_stats[config_id] = len(samples)
            all_samples.extend(samples)
            
        except Exception as e:
            logger.warning(f"åŠ è½½é…ç½®æ–‡ä»¶ {config_file} å¤±è´¥: {e}")
    
    logger.info(f"æ€»å…±åŠ è½½ {len(all_samples)} ä¸ªæµ‹è¯•æ ·æœ¬")
    for config_id, count in config_stats.items():
        logger.info(f"  é…ç½® {config_id}: {count} ä¸ªæ ·æœ¬")
    
    return all_samples

def run_single_gpu_benchmark(args):
    """è¿è¡Œå•GPUæ€§èƒ½åŸºå‡†æµ‹è¯•"""
    logger = logging.getLogger(__name__)
    logger.info("ğŸš€ å¼€å§‹å•GPUæ¨ç†æ€§èƒ½æµ‹è¯•")
    
    try:
        from src.models import ModelManager
        from src.inference import DistributedInferenceEngine
        
        # åˆå§‹åŒ–æ¨¡å‹ç®¡ç†å™¨
        logger.info("åˆå§‹åŒ–æ¨¡å‹ç®¡ç†å™¨...")
        model_manager = ModelManager(args.model_config)
        
        # è®¾ç½®GPUè®¾å¤‡
        torch.cuda.set_device(0)
        model_manager.device = torch.device("cuda:0")
        
        # åŠ è½½æ¨¡å‹
        logger.info("åŠ è½½æ¨¡å‹åˆ°GPU...")
        start_time = time.time()
        model_manager.load_model(local_rank=0)
        load_time = time.time() - start_time
        logger.info(f"æ¨¡å‹åŠ è½½å®Œæˆï¼Œè€—æ—¶: {load_time:.2f} ç§’")
        
        # åˆå§‹åŒ–æ¨ç†å¼•æ“
        logger.info("åˆå§‹åŒ–æ¨ç†å¼•æ“...")
        inference_engine = DistributedInferenceEngine(
            model_manager, 
            args.inference_config
        )
        
        # åŠ è½½æµ‹è¯•æ•°æ®
        logger.info("åŠ è½½æµ‹è¯•æ•°æ®...")
        samples = load_test_dataset(args.dataset, args.max_samples_per_config)
        if not samples:
            logger.error("æµ‹è¯•æ•°æ®åŠ è½½å¤±è´¥")
            return None
        
        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        sample_dicts = []
        for sample in samples:
            sample_dict = {
                'id': sample.id,
                'config_id': sample.config_id,
                'prompt': sample.prompt,
                'prompt_length': sample.prompt_length,
                'generation_length': sample.generation_length,
                'source_type': sample.source_type,
                'metadata': sample.metadata
            }
            sample_dicts.append(sample_dict)
        
        # è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•
        logger.info(f"å¼€å§‹æ¨ç†åŸºå‡†æµ‹è¯•ï¼Œå…± {len(sample_dicts)} ä¸ªæ ·æœ¬")
        logger.info("è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´...")
        
        benchmark_start = time.time()
        results = inference_engine.run_performance_benchmark(sample_dicts)
        benchmark_time = time.time() - benchmark_start
        
        logger.info(f"æ¨ç†åŸºå‡†æµ‹è¯•å®Œæˆï¼Œæ€»è€—æ—¶: {benchmark_time:.2f} ç§’")
        
        # æ¸…ç†èµ„æº
        inference_engine.cleanup()
        torch.cuda.empty_cache()
        
        return results
        
    except Exception as e:
        logger.error(f"å•GPUåŸºå‡†æµ‹è¯•å¤±è´¥: {e}")
        return None

def run_multi_gpu_benchmark(args):
    """è¿è¡Œå¤šGPUæ€§èƒ½åŸºå‡†æµ‹è¯•"""
    logger = logging.getLogger(__name__)
    logger.info(f"ğŸš€ å¼€å§‹å¤šGPUæ¨ç†æ€§èƒ½æµ‹è¯• (ä½¿ç”¨ {args.num_gpus} ä¸ªGPU)")
    
    try:
        # TODO: å®ç°å¤šGPUåˆ†å¸ƒå¼æ¨ç†æµ‹è¯•
        # è¿™é‡Œéœ€è¦ä½¿ç”¨torch.multiprocessingæˆ–torch.distributed
        logger.info("å¤šGPUåŸºå‡†æµ‹è¯•åŠŸèƒ½å¼€å‘ä¸­...")
        logger.info("å½“å‰ç‰ˆæœ¬æ”¯æŒå•GPUæµ‹è¯•ï¼Œå¤šGPUç‰ˆæœ¬å°†åœ¨åç»­æ›´æ–°ä¸­æä¾›")
        
        return None
        
    except Exception as e:
        logger.error(f"å¤šGPUåŸºå‡†æµ‹è¯•å¤±è´¥: {e}")
        return None

def analyze_benchmark_results(results):
    """åˆ†æåŸºå‡†æµ‹è¯•ç»“æœ"""
    logger = logging.getLogger(__name__)
    
    if not results:
        logger.warning("æ²¡æœ‰ç»“æœæ•°æ®å¯åˆ†æ")
        return
    
    logger.info("\n" + "="*60)
    logger.info("ğŸ“Š GPUæ¨ç†æ€§èƒ½åŸºå‡†æµ‹è¯•ç»“æœåˆ†æ")
    logger.info("="*60)
    
    try:
        from src.evaluation import PerformanceEvaluator
        
        evaluator = PerformanceEvaluator("config/inference_config.yaml")
        
        # æŒ‰é…ç½®åˆ†ç»„åˆ†æ
        for config_id, config_data in results.items():
            logger.info(f"\nğŸ“‹ é…ç½® {config_id} æ€§èƒ½ç»Ÿè®¡:")
            
            config_info = config_data['config']
            stats = config_data['statistics']
            
            logger.info(f"   æç¤ºé•¿åº¦: {config_info['prompt_length']} tokens")
            logger.info(f"   ç”Ÿæˆé•¿åº¦: {config_info['generation_length']} tokens")
            logger.info(f"   æ ·æœ¬æ•°é‡: {len(config_data['samples'])}")
            
            # å»¶è¿Ÿç»Ÿè®¡
            logger.info(f"   æ€»å»¶è¿Ÿ: {stats['latency']['total_time']['mean']:.2f} Â± {stats['latency']['total_time']['std']:.2f} ms")
            logger.info(f"   é¦–Token: {stats['latency']['first_token_time']['mean']:.2f} Â± {stats['latency']['first_token_time']['std']:.2f} ms")
            
            # ååé‡ç»Ÿè®¡
            logger.info(f"   ååé‡: {stats['throughput']['mean']:.2f} Â± {stats['throughput']['std']:.2f} tokens/s")
            
            # èµ„æºä½¿ç”¨ç»Ÿè®¡
            if 'resource_utilization' in stats:
                resource_stats = stats['resource_utilization']
                if 'gpu_memory_allocated_mb' in resource_stats:
                    logger.info(f"   GPUå†…å­˜: {resource_stats['gpu_memory_allocated_mb']['mean']:.1f} Â± {resource_stats['gpu_memory_allocated_mb']['std']:.1f} MB")
                if 'gpu_utilization' in resource_stats:
                    logger.info(f"   GPUåˆ©ç”¨ç‡: {resource_stats['gpu_utilization']['mean']:.1f} Â± {resource_stats['gpu_utilization']['std']:.1f} %")
        
        # æ€»ä½“æ€§èƒ½æ€»ç»“
        logger.info(f"\nğŸ¯ æ€»ä½“æ€§èƒ½æ€»ç»“:")
        
        all_throughputs = []
        all_latencies = []
        
        for config_data in results.values():
            stats = config_data['statistics']
            all_throughputs.append(stats['throughput']['mean'])
            all_latencies.append(stats['latency']['total_time']['mean'])
        
        if all_throughputs:
            avg_throughput = sum(all_throughputs) / len(all_throughputs)
            max_throughput = max(all_throughputs)
            avg_latency = sum(all_latencies) / len(all_latencies)
            min_latency = min(all_latencies)
            
            logger.info(f"   å¹³å‡ååé‡: {avg_throughput:.2f} tokens/s")
            logger.info(f"   æœ€å¤§ååé‡: {max_throughput:.2f} tokens/s")
            logger.info(f"   å¹³å‡å»¶è¿Ÿ: {avg_latency:.2f} ms")
            logger.info(f"   æœ€ä½å»¶è¿Ÿ: {min_latency:.2f} ms")
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        results_dir = Path("results")
        results_dir.mkdir(exist_ok=True)
        
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        results_file = results_dir / f"gpu_benchmark_results_{timestamp}.json"
        
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        logger.info(f"\nğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {results_file}")
        
    except Exception as e:
        logger.error(f"ç»“æœåˆ†æå¤±è´¥: {e}")

def main():
    parser = argparse.ArgumentParser(description='GPUæ¨ç†æ€§èƒ½åŸºå‡†æµ‹è¯•')
    
    # åŸºæœ¬å‚æ•°
    parser.add_argument('--dataset', type=str, 
                       default='data/datasets',
                       help='æµ‹è¯•æ•°æ®é›†ç›®å½•è·¯å¾„')
    parser.add_argument('--model-config', type=str, 
                       default='config/model_config.yaml',
                       help='æ¨¡å‹é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--inference-config', type=str, 
                       default='config/inference_config.yaml',
                       help='æ¨ç†é…ç½®æ–‡ä»¶è·¯å¾„')
    
    # GPUå‚æ•°
    parser.add_argument('--num-gpus', type=int, default=1,
                       help='ä½¿ç”¨çš„GPUæ•°é‡')
    parser.add_argument('--gpu-ids', type=int, nargs='+',
                       help='æŒ‡å®šä½¿ç”¨çš„GPU IDåˆ—è¡¨')
    
    # æµ‹è¯•å‚æ•°
    parser.add_argument('--max-samples-per-config', type=int, default=50,
                       help='æ¯ä¸ªé…ç½®çš„æœ€å¤§æ ·æœ¬æ•°é‡')
    parser.add_argument('--warmup-steps', type=int, default=5,
                       help='é¢„çƒ­æ­¥æ•°')
    parser.add_argument('--log-level', type=str, default='INFO',
                       choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'],
                       help='æ—¥å¿—çº§åˆ«')
    
    # æ€§èƒ½ä¼˜åŒ–å‚æ•°
    parser.add_argument('--use-fp16', action='store_true',
                       help='ä½¿ç”¨FP16æ¨ç†')
    parser.add_argument('--use-torch-compile', action='store_true',
                       help='ä½¿ç”¨torch.compileä¼˜åŒ–')
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—
    setup_logging(0, args.log_level)
    logger = logging.getLogger(__name__)
    
    logger.info("="*60)
    logger.info("ğŸ¯ GPUæ¨ç†æ€§èƒ½åŸºå‡†æµ‹è¯•å¯åŠ¨")
    logger.info("="*60)
    
    # éªŒè¯GPUç¯å¢ƒ
    if not validate_gpu_environment(args.num_gpus):
        sys.exit(1)
    
    # æ£€æŸ¥æ•°æ®é›†
    if not Path(args.dataset).exists():
        logger.error(f"æ•°æ®é›†ç›®å½•ä¸å­˜åœ¨: {args.dataset}")
        logger.info("è¯·å…ˆè¿è¡Œ 'python scripts/generate_dataset.py' ç”Ÿæˆæ•°æ®é›†")
        sys.exit(1)
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶
    config_files = [args.model_config, args.inference_config]
    for config_file in config_files:
        if not Path(config_file).exists():
            logger.error(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
            sys.exit(1)
    
    try:
        # è®°å½•å¼€å§‹æ—¶é—´
        total_start_time = time.time()
        
        # è¿è¡ŒåŸºå‡†æµ‹è¯•
        if args.num_gpus == 1:
            results = run_single_gpu_benchmark(args)
        else:
            results = run_multi_gpu_benchmark(args)
        
        # è®°å½•ç»“æŸæ—¶é—´
        total_time = time.time() - total_start_time
        
        if results:
            # åˆ†æç»“æœ
            analyze_benchmark_results(results)
            
            logger.info(f"\nğŸ‰ GPUæ¨ç†æ€§èƒ½åŸºå‡†æµ‹è¯•å®Œæˆï¼")
            logger.info(f"æ€»è€—æ—¶: {total_time:.2f} ç§’")
        else:
            logger.error("åŸºå‡†æµ‹è¯•å¤±è´¥ï¼Œæœªè·å¾—æœ‰æ•ˆç»“æœ")
            sys.exit(1)
        
    except KeyboardInterrupt:
        logger.info("\nâ¹ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        logger.error(f"åŸºå‡†æµ‹è¯•å‘ç”Ÿé”™è¯¯: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
